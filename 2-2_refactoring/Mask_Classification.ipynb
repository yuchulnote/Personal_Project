{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask Classification Refactoring\n",
    "22년 여름 방학에 딥러닝을 갓 배우고, 만들었던 마스크 분류기를 리팩토링\n",
    "\n",
    "하게 된 이유 : 그 동안 많은 경험을 위해 닥치는 대로 딥러닝을 사용해보고, 여러 지식을 습득하기 바밨었으나, 이제는 이전 작품을 다시 리팩토링 및 코드를 최대한 gpt의 도움 없이 짜보면서 내실을 다지고 싶었기 때문."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from PIL import Image\n",
    "import glob\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "import torch\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from activation import relu\n",
    "from commons import col2im, im2col\n",
    "from layers import batch_normalization, convolution, fc_layer, pooling\n",
    "from losses import cross_entropy_loss, softmax_with_loss, softmax\n",
    "from models import vgg6\n",
    "from optimizer import adam\n",
    "from Trainer import trainer\n",
    "from utils import get_grad, graph, shuffle_dataset, split_dataset, visualize_result, earlystop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'GPU 사용 가능 여부: {torch.cuda.is_available()}')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"CPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 난수 생성을 위한 시드 설정\n",
    "SEED = 777\n",
    "\n",
    "# CPU 환경을 위한 PyTorch 난수 생성기에 시드 설정\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# 현재 GPU를 위한 PyTorch 난수 생성기에 시드 설정\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# cuDNN의 결정적(deterministic) 알고리즘 사용 여부 설정\n",
    "# False로 설정할 경우, 비결정적 알고리즘이 허용되어 성능이 향상될 수 있지만, 재현성이 감소할 수 있음\n",
    "torch.backends.cudnn.deterministic = False\n",
    "\n",
    "# cuDNN에서 최적의 알고리즘을 자동으로 찾도록 설정\n",
    "# True로 설정할 경우, 고정된 입력 크기에 대해 더 빠른 성능을 제공하지만, 다양한 크기의 입력에서는 성능 저하가 발생할 수 있음\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 디렉토리 설정 해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDataset(Dataset):\n",
    "    \"\"\"\n",
    "    마스크 착용 여부를 구별하는 이미지 데이터셋 클래스.\n",
    "\n",
    "    이 클래스는 주어진 디렉토리에서 마스크 착용 여부를 구분하는 이미지 데이터셋을 로드하고,\n",
    "    albumentations 라이브러리를 사용한 이미지 변환을 적용한다.\n",
    "\n",
    "    Parameters:\n",
    "        data_dir (str): 데이터셋이 위치한 디렉토리 경로.\n",
    "        mode (str): 데이터셋 모드 ('train', 'val', 'test').\n",
    "        transform (albumentations.Compose): 이미지에 적용할 변환.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, mode, transform=None):\n",
    "        self.all_data = sorted(glob.glob(os.path.join(data_dir, mode, '*', '*')))\n",
    "        self.transform = transform\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        인덱스에 해당하는 데이터를 반환합니다.\n",
    "\n",
    "        Parameters:\n",
    "            index (int): 데이터셋에서 가져올 샘플의 인덱스.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (변환된 이미지, 레이블).\n",
    "        \"\"\"\n",
    "        data_path = self.all_data[index]\n",
    "        img = Image.open(data_path)\n",
    "        label = 0 if os.path.basename(data_path).startswith(\"Mask\") else 1\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=np.array(img))[\"image\"]\n",
    "            \n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        데이터셋의 전체 길이를 반환합니다.\n",
    "\n",
    "        Returns:\n",
    "            int: 데이터셋의 전체 길이.\n",
    "        \"\"\"\n",
    "        return len(self.all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# albumentations을 사용한 데이터 변환 정의\n",
    "data_transforms = {\n",
    "    'train': A.Compose([\n",
    "        A.RandomRotate90(),\n",
    "        A.Flip(),\n",
    "        A.Transpose(),\n",
    "        A.OneOf([\n",
    "            A.MotionBlur(p=.2),\n",
    "            A.MedianBlur(blur_limit=3, p=.1),\n",
    "            A.Blur(blur_limit=3, p=.1),\n",
    "        ], p=0.2),\n",
    "        A.OneOf([\n",
    "            A.CLAHE(clip_limit=2),\n",
    "            A.Sharpen(),\n",
    "            A.Emboss(),\n",
    "            A.RandomBrightnessContrast(),\n",
    "        ], p=0.3),\n",
    "        A.HueSaturationValue(p=0.3),\n",
    "        ToTensorV2()\n",
    "    ]),\n",
    "    'val': A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 로딩, 실제 데이터셋 받아서 경로 수정 필요\n",
    "data_dir = './data'\n",
    "split_dir = './splitdata'\n",
    "\n",
    "# 데이터셋 분할\n",
    "split_dataset.split_dataset(data_dir, split_dir)\n",
    "\n",
    "train_dataset = MaskDataset(split_dir, 'train', transform=data_transforms['train'])\n",
    "val_dataset = MaskDataset(split_dir, 'val', transform=data_transforms['val'])\n",
    "test_dataset = MaskDataset(split_dir, 'test', transform=data_transforms['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "torch의 DataLoader의 shuffle 기능을 사용하지 않고, 커스텀한 shuffle 함수로 사용하기 위한 코드\n",
    "\"\"\"\n",
    "\n",
    "x = []\n",
    "t = []\n",
    "\n",
    "for img, label in train_dataset:\n",
    "    x.append(img.numpy())\n",
    "    t.append(label)\n",
    "\n",
    "x = np.array(x)\n",
    "# x 배열이 4차원이 아니라면 차원을 증가시킵니다.\n",
    "# 예를 들어, x 배열이 (샘플 수, 높이, 너비, 채널 수) 형태가 아닌 경우\n",
    "if x.ndim < 4:\n",
    "    x = np.expand_dims(x, axis=1)  # 채널 차원 추가\n",
    "\n",
    "t = np.array(t)\n",
    "\n",
    "# 데이터셋 섞기\n",
    "x_shuffled, t_shuffled = shuffle_dataset.shuffle_dataset(x, t)\n",
    "\n",
    "# TensorDataset으로 변환\n",
    "tensor_x = torch.Tensor(x_shuffled)\n",
    "tensor_t = torch.Tensor(t_shuffled)\n",
    "\n",
    "shuffled_trainset = TensorDataset(tensor_x, tensor_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 300\n",
    "learning_rate = 0.0001\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로더\n",
    "train_loader = DataLoader(shuffled_trainset, batch_size=batch_size, shuffle=False, drop_last=True, pin_memory=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg6.VGG6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = trainer.Trainer(model, x_train_loader = train_loader, x_test_loader = test_loader,\n",
    "                          epochs=num_epochs, mini_batch_size=batch_size,\n",
    "                          optimizer=adam.Adam, evaluate_sample_num_per_epoch=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
