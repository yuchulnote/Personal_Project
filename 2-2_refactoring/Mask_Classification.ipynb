{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask Classification Refactoring\n",
    "22년 여름 방학에 딥러닝을 갓 배우고, 만들었던 마스크 분류기를 리팩토링\n",
    "\n",
    "하게 된 이유 : 그 동안 많은 경험을 위해 닥치는 대로 딥러닝을 사용해보고, 여러 지식을 습득하기 바밨었으나, 이제는 이전 작품을 다시 리팩토링 및 코드를 최대한 gpt의 도움 없이 짜보면서 내실을 다지고 싶었기 때문.\n",
    "\n",
    "저번에 잘 안되었던 이유\n",
    "- Trainer에서 test_acc 변수가 제대로 설정되어 있지 않았음\n",
    "- DataLoader에서 직접 만든 customDataset class로 선언하지 않았음\n",
    "- 데이터셋이 kaggle에서 받아오다보니, 외국인 사진이 많아, 동양인처럼 눈이 비교적 작고 눈썹을 가리는 머리스타일이 없음 + 데이터가 조잡함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from PIL import Image\n",
    "import glob\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "import torch\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import time\n",
    "import IProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from activation import relu\n",
    "from commons import col2im, im2col\n",
    "from layers import batch_normalization, convolution, fc_layer, pooling\n",
    "from losses import cross_entropy_loss, softmax_with_loss, softmax\n",
    "from models import vgg6\n",
    "from optimizer import adam\n",
    "from Trainer.trainer import Trainer\n",
    "from utils import get_grad, graph, shuffle_dataset, split_dataset, visualize_result, earlystop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 사용 가능 여부: False\n"
     ]
    }
   ],
   "source": [
    "print(f'GPU 사용 가능 여부: {torch.cuda.is_available()}')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"CPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 난수 생성을 위한 시드 설정\n",
    "SEED = 777\n",
    "\n",
    "# CPU 환경을 위한 PyTorch 난수 생성기에 시드 설정\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# 현재 GPU를 위한 PyTorch 난수 생성기에 시드 설정\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# cuDNN의 결정적(deterministic) 알고리즘 사용 여부 설정\n",
    "# False로 설정할 경우, 비결정적 알고리즘이 허용되어 성능이 향상될 수 있지만, 재현성이 감소할 수 있음\n",
    "torch.backends.cudnn.deterministic = False\n",
    "\n",
    "# cuDNN에서 최적의 알고리즘을 자동으로 찾도록 설정\n",
    "# True로 설정할 경우, 고정된 입력 크기에 대해 더 빠른 성능을 제공하지만, 다양한 크기의 입력에서는 성능 저하가 발생할 수 있음\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 디렉토리 설정 해야함\n",
    "data_dir = r'C:\\Users\\A\\Desktop\\data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDataset(Dataset):\n",
    "    \"\"\"\n",
    "    마스크 착용 여부를 구별하는 이미지 데이터셋 클래스.\n",
    "\n",
    "    이 클래스는 주어진 디렉토리에서 마스크 착용 여부를 구분하는 이미지 데이터셋을 로드하고,\n",
    "    albumentations 라이브러리를 사용한 이미지 변환을 적용한다.\n",
    "\n",
    "    Parameters:\n",
    "        data_dir (str): 데이터셋이 위치한 디렉토리 경로.\n",
    "        mode (str): 데이터셋 모드 ('train', 'val', 'test').\n",
    "        transform (albumentations.Compose): 이미지에 적용할 변환.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, mode, transform=None):\n",
    "        self.all_data = sorted(glob.glob(os.path.join(data_dir, mode, '*', '*')))\n",
    "        self.transform = transform\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        인덱스에 해당하는 데이터를 반환합니다.\n",
    "\n",
    "        Parameters:\n",
    "            index (int): 데이터셋에서 가져올 샘플의 인덱스.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (변환된 이미지, 레이블).\n",
    "        \"\"\"\n",
    "        data_path = self.all_data[index]\n",
    "        img = Image.open(data_path)\n",
    "        label = 0 if os.path.basename(data_path).startswith(\"Mask\") else 1\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=np.array(img))[\"image\"]\n",
    "            \n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        데이터셋의 전체 길이를 반환합니다.\n",
    "\n",
    "        Returns:\n",
    "            int: 데이터셋의 전체 길이.\n",
    "        \"\"\"\n",
    "        return len(self.all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# albumentations을 사용한 데이터 변환 정의\n",
    "data_transforms = {\n",
    "    'train': A.Compose([\n",
    "        A.RandomRotate90(),\n",
    "        A.Flip(),\n",
    "        A.Transpose(),\n",
    "        A.OneOf([\n",
    "            A.MotionBlur(p=.2),\n",
    "            A.MedianBlur(blur_limit=3, p=.1),\n",
    "            A.Blur(blur_limit=3, p=.1),\n",
    "        ], p=0.2),\n",
    "        A.OneOf([\n",
    "            A.CLAHE(clip_limit=2),\n",
    "            A.Sharpen(),\n",
    "            A.Emboss(),\n",
    "            A.RandomBrightnessContrast(),\n",
    "        ], p=0.3),\n",
    "        A.HueSaturationValue(p=0.3),\n",
    "        A.Resize(224, 224),\n",
    "        ToTensorV2()\n",
    "    ]),\n",
    "    'val': A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 로딩\n",
    "split_dir = r'C:\\Users\\A\\Desktop\\data\\splitdata'\n",
    "\n",
    "# 데이터셋 분할(필요할 시, 주석 해체 후 사용)\n",
    "# split_dataset.split_dataset(data_dir, split_dir)\n",
    "\n",
    "train_dataset = MaskDataset(split_dir, 'train', transform=data_transforms['train'])\n",
    "val_dataset = MaskDataset(split_dir, 'val', transform=data_transforms['val'])\n",
    "test_dataset = MaskDataset(split_dir, 'test', transform=data_transforms['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# torch의 DataLoader의 shuffle 기능을 사용하지 않고, 커스텀한 shuffle 함수로 사용하기 위한 코드\n",
    "# \"\"\"\n",
    "\n",
    "# x = []\n",
    "# t = []\n",
    "\n",
    "# for img, label in train_dataset:\n",
    "#     x.append(img.numpy())\n",
    "#     t.append(label)\n",
    "\n",
    "# x = np.array(x)\n",
    "# # x 배열이 4차원이 아니라면 차원을 증가시킵니다.\n",
    "# # 예를 들어, x 배열이 (샘플 수, 높이, 너비, 채널 수) 형태가 아닌 경우\n",
    "# if x.ndim < 4:\n",
    "#     x = np.expand_dims(x, axis=1)  # 채널 차원 추가\n",
    "\n",
    "# t = np.array(t)\n",
    "\n",
    "# # 데이터셋 섞기\n",
    "# x_shuffled, t_shuffled = shuffle_dataset.shuffle_dataset(x, t)\n",
    "\n",
    "# # TensorDataset으로 변환\n",
    "# tensor_x = torch.Tensor(x_shuffled)\n",
    "# tensor_t = torch.Tensor(t_shuffled)\n",
    "\n",
    "# shuffled_trainset = TensorDataset(tensor_x, tensor_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 300\n",
    "learning_rate = 0.0001\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로더\n",
    "# train_loader = DataLoader(shuffled_trainset, batch_size=batch_size, shuffle=False, drop_last=True, pin_memory=True, num_workers=num_workers)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True, pin_memory=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg6.VGG6(\n",
    "    input_dim=(3, 224, 224),\n",
    "    conv_param_1={'filter_num': 16, 'filter_size': 3, 'pad': 1, 'stride': 1},\n",
    "    conv_param_2={'filter_num': 32, 'filter_size': 3, 'pad': 1, 'stride': 1},\n",
    "    conv_param_3={'filter_num': 64, 'filter_size': 3, 'pad': 1, 'stride': 1},\n",
    "    conv_param_4={'filter_num': 128, 'filter_size': 3, 'pad': 1, 'stride': 1},\n",
    "    hidden_size=50,\n",
    "    output_size=2  \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, x_train_loader = train_loader, x_test_loader = test_loader,\n",
    "                          epochs=num_epochs, mini_batch_size=batch_size,\n",
    "                          optimizer='adam', evaluate_sample_num_per_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myuchul\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\A\\Desktop\\yuchul_study\\Personal_Project\\2-2_refactoring\\wandb\\run-20231205_013652-989xkh1j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yuchul/Mask_Classification/runs/989xkh1j' target=\"_blank\">visionary-terrain-8</a></strong> to <a href='https://wandb.ai/yuchul/Mask_Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yuchul/Mask_Classification' target=\"_blank\">https://wandb.ai/yuchul/Mask_Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yuchul/Mask_Classification/runs/989xkh1j' target=\"_blank\">https://wandb.ai/yuchul/Mask_Classification/runs/989xkh1j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|          | 0/544 [00:45<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (32,401408) and (3136,50) not aligned: 401408 (dim 1) != 3136 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\A\\Desktop\\yuchul_study\\Personal_Project\\2-2_refactoring\\Mask_Classification.ipynb 셀 15\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/A/Desktop/yuchul_study/Personal_Project/2-2_refactoring/Mask_Classification.ipynb#X20sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m early_stop \u001b[39m=\u001b[39m earlystop\u001b[39m.\u001b[39mEarlyStopping(patience\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, save_path\u001b[39m=\u001b[39mcheckout_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/A/Desktop/yuchul_study/Personal_Project/2-2_refactoring/Mask_Classification.ipynb#X20sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# 학습 시작\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/A/Desktop/yuchul_study/Personal_Project/2-2_refactoring/Mask_Classification.ipynb#X20sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m train_losses, val_losses \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain(current_epochs\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\A\\Desktop\\yuchul_study\\Personal_Project\\2-2_refactoring\\Trainer\\trainer.py:116\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, current_epochs)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[39m신경망 모델을 훈련하는 메소드.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \n\u001b[0;32m    112\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[39m    current_epochs (int): 현재까지 완료된 에폭 수.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs):\n\u001b[1;32m--> 116\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step()\n\u001b[0;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m (epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39m5\u001b[39m \u001b[39m==\u001b[39m  \u001b[39m0\u001b[39m:\n\u001b[0;32m    119\u001b[0m         test_data, test_labels \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_loader))\n",
      "File \u001b[1;32mc:\\Users\\A\\Desktop\\yuchul_study\\Personal_Project\\2-2_refactoring\\Trainer\\trainer.py:75\u001b[0m, in \u001b[0;36mTrainer.train_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m# tqdm을 이용하여 진행 상황 시각화\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39mfor\u001b[39;00m x_batch, t_batch \u001b[39min\u001b[39;00m tqdm(dataloader, desc\u001b[39m=\u001b[39mname):\n\u001b[0;32m     74\u001b[0m     \u001b[39m# 그래디언트 계산 및 최적화\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m     grads \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnetwork\u001b[39m.\u001b[39;49mgradient(x_batch, t_batch)\n\u001b[0;32m     76\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork\u001b[39m.\u001b[39mparams, grads)\n\u001b[0;32m     78\u001b[0m     \u001b[39m# 손실 계산\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\A\\Desktop\\yuchul_study\\Personal_Project\\2-2_refactoring\\models\\vgg6.py:185\u001b[0m, in \u001b[0;36mVGG6.gradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39m그래디언트를 계산합니다.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[39m    dict: 가중치와 편향에 대한 그래디언트.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[39m# 순전파\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss(x, t)\n\u001b[0;32m    187\u001b[0m \u001b[39m# 역전파\u001b[39;00m\n\u001b[0;32m    188\u001b[0m dout \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\A\\Desktop\\yuchul_study\\Personal_Project\\2-2_refactoring\\models\\vgg6.py:143\u001b[0m, in \u001b[0;36mVGG6.loss\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss\u001b[39m(\u001b[39mself\u001b[39m, x, t):\n\u001b[0;32m    133\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[39m    손실 함수를 계산합니다.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39m        float: 계산된 손실 값.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 143\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(x, train_flg\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    144\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_layer\u001b[39m.\u001b[39mforward(y, t)\n",
      "File \u001b[1;32mc:\\Users\\A\\Desktop\\yuchul_study\\Personal_Project\\2-2_refactoring\\models\\vgg6.py:127\u001b[0m, in \u001b[0;36mVGG6.predict\u001b[1;34m(self, x, train_flg, first_flg)\u001b[0m\n\u001b[0;32m    125\u001b[0m         x \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mforward(x, train_flg)\n\u001b[0;32m    126\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         x \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mforward(x)\n\u001b[0;32m    129\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\A\\Desktop\\yuchul_study\\Personal_Project\\2-2_refactoring\\layers\\fc_layer.py:54\u001b[0m, in \u001b[0;36mFC_Layer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m x\n\u001b[0;32m     53\u001b[0m \u001b[39m# 완전 연결 계층의 연산 수행\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb\n\u001b[0;32m     56\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (32,401408) and (3136,50) not aligned: 401408 (dim 1) != 3136 (dim 0)"
     ]
    }
   ],
   "source": [
    "# 현재 시간에서 분까지만 잘라내기\n",
    "now = time.localtime()\n",
    "# YYYYMMDDHHMM 형태로 저장\n",
    "now = time.strftime('%Y%m%d%H%M', now)\n",
    "\n",
    "checkout_path = fr\"./checkout/{now}\"\n",
    "os.makedirs(checkout_path, exist_ok=True)\n",
    "\n",
    "wandb.init(project='Mask_Classification', config={\n",
    "    'learning_rate' : 0.001,\n",
    "    'epochs' : 300,\n",
    "    'batch_size' : batch_size,\n",
    "    'dataset' : 'kaggle',\n",
    "    'architecture' : 'VGG6',\n",
    "    'optimizer' : 'Adam',\n",
    "    'criterion' : 'Cross Entropy Loss',\n",
    "    'lr_scheduler' : 'None',\n",
    "    'amp' : None,\n",
    "    'pin_memory' : True,\n",
    "    'non_blocking' : None,\n",
    "    'accumulation_steps' : None,\n",
    "    'num_workers' : num_workers,\n",
    "    'EarlyStopping' : True\n",
    "})\n",
    "\n",
    "config = wandb.config\n",
    "\n",
    "# Early Stop 설정\n",
    "early_stop = earlystop.EarlyStopping(patience=10, verbose=True, save_path=checkout_path)\n",
    "\n",
    "# 학습 시작\n",
    "train_losses, val_losses = trainer.train(current_epochs=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
