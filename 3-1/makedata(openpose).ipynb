{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.utils\n",
    "from PIL import Image\n",
    "import glob\n",
    "import sys, os\n",
    "sys.path.append(os.pardir) # 부모 디렉토리의 파일을 가져올 수 있도록 설정\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "import torch\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "from imutils.video import VideoStream\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import PIL.ImageOps\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"현재 디렉토리 위치: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder = \"Project\"\n",
    "#project_dir = \"Bowling\"\n",
    "#base_path = Path(\"C:\\\\Users\\yuddo\\Yuchul\")\n",
    "#project_path = base_path / folder / project_dir\n",
    "#os.chdir(project_path)\n",
    "#for x in list(project_path.glob(\"*\")):\n",
    "#    if x.is_dir():\n",
    "#        dir_name = str(x.relative_to(project_path))\n",
    "#        os.rename(dir_name, dir_name.split(\" \", 1)[0])\n",
    "#print(f\"현재 디렉토리 위치: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = Path().absolute()\n",
    "data_path = current_path / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"현재 디렉토리 위치: {}\".format(current_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (data_path / \"user\").exists():\n",
    "    print(\"폴더가 있습니다! 이어서 진행하세요~\")\n",
    "else: print(\"없습니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dir = './data/user'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './data/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_keypoints(frame, net, threshold, BODY_PARTS, now_frame, total_frame):\n",
    "    global points\n",
    "    \n",
    "    # 입력 이미지 사이즈 정의\n",
    "    image_height = 368\n",
    "    image_width = 368\n",
    "    \n",
    "    # 네트워크에 넣기 위한 전처리\n",
    "    input_blob = cv2.dnn.blobFromImage(frame, 1.0/255, (image_width, image_height), (0, 0, 0), swapRB=False, crop=False)\n",
    "    \n",
    "    # 전처리된 blob 네트워크에 입력\n",
    "    net.setInput(input_blob)\n",
    "\n",
    "    # 결과 받아오기\n",
    "    out = net.forward()\n",
    "    # The output is a 4D matrix :\n",
    "    # The first dimension being the image ID ( in case you pass more than one image to the network ).\n",
    "    # The second dimension indicates the index of a keypoint.\n",
    "    # The model produces Confidence Maps and Part Affinity maps which are all concatenated.\n",
    "    # For COCO model it consists of 57 parts – 18 keypoint confidence Maps + 1 background + 19*2 Part Affinity Maps. Similarly, for MPI, it produces 44 points.\n",
    "    # We will be using only the first few points which correspond to Keypoints.\n",
    "    # The third dimension is the height of the output map.\n",
    "    out_height = out.shape[2]\n",
    "    # The fourth dimension is the width of the output map.\n",
    "    out_width = out.shape[3]\n",
    "\n",
    "    # 원본 이미지의 높이, 너비를 받아오기\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    # 포인트 리스트 초기화\n",
    "    points = []\n",
    "\n",
    "    print(f\"============================== frame: {now_frame:.0f} / {total_frame:.0f} ==============================\")\n",
    "    for i in range(len(BODY_PARTS)):\n",
    "\n",
    "        # 신체 부위의 confidence map\n",
    "        prob_map = out[0, i, :, :]\n",
    "\n",
    "        # 최소값, 최대값, 최소값 위치, 최대값 위치\n",
    "        min_val, prob, min_loc, point = cv2.minMaxLoc(prob_map)\n",
    "\n",
    "        # 원본 이미지에 맞게 포인트 위치 조정\n",
    "        x = (frame_width * point[0]) / out_width\n",
    "        x = int(x)\n",
    "        y = (frame_height * point[1]) / out_height\n",
    "        y = int(y)\n",
    "\n",
    "        if prob > threshold:  # [pointed]\n",
    "            cv2.circle(frame, (x, y), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frame, str(i), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "            points.append((x, y))\n",
    "            print(f\"[pointed] {BODY_PARTS[i]} ({i}) => prob: {prob:.5f} / x: {x} / y: {y}\")\n",
    "\n",
    "        else:  # [not pointed]\n",
    "            cv2.circle(frame, (x, y), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frame, str(i), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "            points.append(None)\n",
    "            print(f\"[not pointed] {BODY_PARTS[i]} ({i}) => prob: {prob:.5f} / x: {x} / y: {y}\")\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_keypoints_with_lines(frame, POSE_PAIRS):\n",
    "    for pair in POSE_PAIRS:\n",
    "        part_a = pair[0]  # 0 (Head)\n",
    "        part_b = pair[1]  # 1 (Neck)\n",
    "        if points[part_a] and points[part_b]:\n",
    "            print(f\"[linked] {part_a} {points[part_a]} <=> {part_b} {points[part_b]}\")\n",
    "            cv2.line(frame, points[part_a], points[part_b], (0, 255, 0), 3)\n",
    "        else:\n",
    "            print(f\"[not linked] {part_a} {points[part_a]} <=> {part_b} {points[part_b]}\")\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_keypoints_with_lines_video(proto_file, weights_file, video_path, threshold, BODY_PARTS, POSE_PAIRS):\n",
    "\n",
    "    # 비디오 읽어오기\n",
    "    capture = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # 네트워크 불러오기\n",
    "    net = cv2.dnn.readNetFromCaffe(proto_file, weights_file)\n",
    "    \n",
    "    # GPU 사용\n",
    "    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "    if capture.isOpened():\n",
    "        fps = capture.get(cv2.CAP_PROP_FPS)\n",
    "        frame_width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        output = cv2.VideoWriter(\"output.avi\", fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    while True:\n",
    "        now_frame_boy = capture.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "        total_frame_boy = capture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "        if now_frame_boy == total_frame_boy:\n",
    "            break\n",
    "\n",
    "        ret, frame_boy = capture.read()\n",
    "        frame_boy = output_keypoints(frame=frame_boy, net=net, threshold=threshold, BODY_PARTS=BODY_PARTS, now_frame=now_frame_boy, total_frame=total_frame_boy)\n",
    "        frame_boy = output_keypoints_with_lines(frame=frame_boy, POSE_PAIRS=POSE_PAIRS)\n",
    "        cv2.imshow(\"Output_Keypoints\", frame_boy)\n",
    "        output.write(frame_boy)\n",
    "        \n",
    "        if cv2.waitKey(10) == 27:  # esc 입력시 종료\n",
    "            break\n",
    "\n",
    "    capture.release()\n",
    "    output.release()\n",
    "    print(\"Output Video saved successfully\")\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BODY_PARTS_MPI = {0: \"Head\", 1: \"Neck\", 2: \"RShoulder\", 3: \"RElbow\", 4: \"RWrist\",\n",
    "                  5: \"LShoulder\", 6: \"LElbow\", 7: \"LWrist\", 8: \"RHip\", 9: \"RKnee\",\n",
    "                  10: \"RAnkle\", 11: \"LHip\", 12: \"LKnee\", 13: \"LAnkle\", 14: \"Chest\",\n",
    "                  15: \"Background\"}\n",
    "\n",
    "POSE_PAIRS_MPI = [[0, 1], [1, 2], [1, 5], [1, 14], [2, 3], [3, 4], [5, 6],\n",
    "                  [6, 7], [8, 9], [9, 10], [11, 12], [12, 13], [14, 8], [14, 11]]\n",
    "\n",
    "BODY_PARTS_COCO = {0: \"Nose\", 1: \"Neck\", 2: \"RShoulder\", 3: \"RElbow\", 4: \"RWrist\",\n",
    "                   5: \"LShoulder\", 6: \"LElbow\", 7: \"LWrist\", 8: \"RHip\", 9: \"RKnee\",\n",
    "                   10: \"RAnkle\", 11: \"LHip\", 12: \"LKnee\", 13: \"LAnkle\", 14: \"REye\",\n",
    "                   15: \"LEye\", 16: \"REar\", 17: \"LEar\", 18: \"Background\"}\n",
    "\n",
    "POSE_PAIRS_COCO = [[0, 1], [0, 14], [0, 15], [1, 2], [1, 5], [1, 8], [1, 11], [2, 3], [3, 4],\n",
    "                   [5, 6], [6, 7], [8, 9], [9, 10], [12, 13], [11, 12], [14, 16], [15, 17]]\n",
    "\n",
    "BODY_PARTS_BODY_25 = {0: \"Nose\", 1: \"Neck\", 2: \"RShoulder\", 3: \"RElbow\", 4: \"RWrist\",\n",
    "                      5: \"LShoulder\", 6: \"LElbow\", 7: \"LWrist\", 8: \"MidHip\", 9: \"RHip\",\n",
    "                      10: \"RKnee\", 11: \"RAnkle\", 12: \"LHip\", 13: \"LKnee\", 14: \"LAnkle\",\n",
    "                      15: \"REye\", 16: \"LEye\", 17: \"REar\", 18: \"LEar\", 19: \"LBigToe\",\n",
    "                      20: \"LSmallToe\", 21: \"LHeel\", 22: \"RBigToe\", 23: \"RSmallToe\", 24: \"RHeel\", 25: \"Background\"}\n",
    "\n",
    "POSE_PAIRS_BODY_25 = [[0, 1], [0, 15], [0, 16], [1, 2], [1, 5], [1, 8], [8, 9], [8, 12], [9, 10], [12, 13], [2, 3],\n",
    "                      [3, 4], [5, 6], [6, 7], [10, 11], [13, 14], [15, 17], [16, 18], [14, 21], [19, 21], [20, 21],\n",
    "                      [11, 24], [22, 24], [23, 24]]\n",
    "\n",
    "# 신경 네트워크의 구조를 지정하는 prototxt 파일 (다양한 계층이 배열되는 방법 등)\n",
    "protoFile_mpi = \"C:/Users\\yuddo\\Yuchul\\Project\\Bowling\\openpose\\models\\pose\\mpi\\pose_deploy_linevec.prototxt\"\n",
    "protoFile_mpi_faster = \"C:\\\\Users\\yuddo\\Yuchul\\Project\\Bowling\\openpose\\models\\pose\\mpi\\pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "protoFile_coco = \"C:\\\\Users\\yuddo\\Yuchul\\Project\\Bowling\\openpose\\models\\pose\\coco\\pose_deploy_linevec.prototxt\"\n",
    "protoFile_body_25 = \"C:\\\\Users\\yuddo\\Yuchul\\Project\\Bowling\\openpose-master\\models\\pose\\body_25\\pose_deploy.prototxt\"\n",
    "\n",
    "# 훈련된 모델의 weight 를 저장하는 caffemodel 파일\n",
    "weightsFile_mpi = \"C:\\\\Users\\yuddo\\Yuchul\\Project\\Bowling\\openpose\\models\\pose\\mpi\\pose_iter_160000.caffemodel\"\n",
    "weightsFile_coco = \"C:\\\\Users\\yuddo\\Yuchul\\Project\\Bowling\\openpose\\models\\pose\\coco\\pose_iter_440000.caffemodel\"\n",
    "weightsFile_body_25 = \"C:/Users/yuddo/Yuchul/Project/Bowling/openpose-master/models/pose/body_25/pose_iter_584000.caffemodel\"\n",
    "\n",
    "# 비디오 경로\n",
    "man = \"C:/Users/yuddo/Yuchul/Project/Bowling/data/pro/pro_1.mp4\"\n",
    "\n",
    "# 키포인트를 저장할 빈 리스트\n",
    "points = []\n",
    "\n",
    "#output_keypoints_with_lines_video(proto_file=protoFile_mpi_faster, weights_file=weightsFile_mpi, video_path=man,\n",
    "#                                 threshold=0.1, BODY_PARTS=BODY_PARTS_MPI, POSE_PAIRS=POSE_PAIRS_MPI)\n",
    "\n",
    "output_keypoints_with_lines_video(proto_file=protoFile_coco, weights_file=weightsFile_coco, video_path=man,\n",
    "                                  threshold=0.1, BODY_PARTS=BODY_PARTS_COCO, POSE_PAIRS=POSE_PAIRS_COCO)\n",
    "\n",
    "#output_keypoints_with_lines_video(proto_file=protoFile_body_25, weights_file=weightsFile_body_25, video_path=man,\n",
    "#                                 threshold=0.1, BODY_PARTS=BODY_PARTS_BODY_25, POSE_PAIRS=POSE_PAIRS_BODY_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"C:/Users/yuddo/Yuchul/Project/Bowling/data/user/1.mp4\"\n",
    "\n",
    "output_keypoints_with_lines_video(proto_file=protoFile_coco, weights_file=weightsFile_coco, video_path=user,\n",
    "                                  threshold=0.1, BODY_PARTS=BODY_PARTS_COCO, POSE_PAIRS=POSE_PAIRS_COCO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_video_into_frames(video_path, output_folder):\n",
    "    # 비디오 읽어오기\n",
    "    capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_path = f\"{output_folder}/frame_{frame_count}.jpg\"\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    capture.release()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
